{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4e7c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepctr.models import xDeepFM\n",
    "from deepctr.feature_column  import  SparseFeat, DenseFeat,get_feature_names\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4992fda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading criteo_sample data\n",
    "data = pd.read_csv('./grocery_data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb504db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['purchased'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f9867",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce36485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorising the features into sparse/dense feature set \n",
    "\n",
    "# dense features are quantitative in nature\n",
    "dense_features = ['age', 'price',]\n",
    "\n",
    "#sparse features are categorical in nature\n",
    "sparse_features = ['user_id', 'product_id', 'gender', 'location', 'category',  'brand']\n",
    "\n",
    "# data imputation for missing values\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "data[dense_features] = data[dense_features].fillna(0,)\n",
    "# creating target variable\n",
    "target = ['purchased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb34d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding function\n",
    "def encoding(data,feat,encoder):\n",
    "    data[feat] = encoder.fit_transform(data[feat])\n",
    "# encoding for categorical features\n",
    "[encoding(data,feat,LabelEncoder()) for feat in sparse_features]\n",
    "# Using normalization for dense feature\n",
    "mms = MinMaxScaler(feature_range=(0,1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])\n",
    "# creating a 4 bit embedding for every sparse feature\n",
    "sparse_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].nunique(),embedding_dim=4) \\\n",
    "for i,feat in enumerate(sparse_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb0232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_lookup = {}\n",
    "users_lookup = {}\n",
    "\n",
    "for i in range(len(data)):\n",
    "    items_lookup[data['product_id'].iloc[i]] = data.iloc[i][['category','price','brand']]\n",
    "    users_lookup[data['user_id'].iloc[i]] = data.iloc[i][['age','location','gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee903257",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d70bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all movie IDs\n",
    "all_productIds = data['product_id'].unique()\n",
    "\n",
    "user_item_set = set(zip(data['user_id'], data['product_id']))\n",
    "\n",
    "# This is the set of items that each user has interaction with\n",
    "user_items_dataset = set(zip(data['user_id'], data['product_id'], \\\n",
    "                         data['age'], data['gender'], \\\n",
    "                        data['location'], data['category'], \\\n",
    "                         data['price'], data['brand'], data['purchased']))\n",
    "\n",
    "\n",
    "# 4:1 ratio of negative to positive samples\n",
    "num_negatives = 4\n",
    "\n",
    "for (user, item, age, gender, location, category, price, brand, purchased) in user_items_dataset:\n",
    "    \n",
    "    for _ in range(num_negatives):\n",
    "        # randomly select an item\n",
    "        negative_item = np.random.choice(all_productIds)\n",
    "        # check that the user has not interacted with this item\n",
    "        while (user, negative_item) in user_item_set:\n",
    "            negative_item = np.random.choice(all_productIds)\n",
    "            \n",
    "        df2 = pd.DataFrame({\n",
    "                'user_id': [user], \n",
    "                'product_id': [negative_item], \n",
    "                'age': [age], \n",
    "                'gender': [gender],\n",
    "                'location': [location], \n",
    "                'category': [items_lookup[negative_item]['category']],\n",
    "                'price': [items_lookup[negative_item]['price']], \n",
    "                'brand': [items_lookup[negative_item]['brand']], \n",
    "                'purchased': [0]\n",
    "                })\n",
    "        \n",
    "        data = data.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca84ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dense feat\n",
    "dense_feature_columns = [DenseFeat(feat, 1) for feat in dense_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8258eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20a699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dense feat\n",
    "dense_feature_columns = [DenseFeat(feat, 1) for feat in dense_features]\n",
    "\n",
    "# features to be used for dnn part of xdeepfm\n",
    "dnn_feature_columns = sparse_feature_columns + dense_feature_columns\n",
    "# features to be used for linear part of xdeepfm\n",
    "linear_feature_columns = sparse_feature_columns + dense_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "# creating train test splits\n",
    "train, test = train_test_split(data, test_size=0.1)\n",
    "train_model_input = {name:train[name].values for name in feature_names}\n",
    "test_model_input = {name:test[name].values for name in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d74878",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e048b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xDeepFM(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(512, 512),\\\n",
    "cin_layer_size=(512, 512), \\\n",
    "cin_split_half=True, cin_activation='relu'\\\n",
    ",l2_reg_linear=1e-05,\\\n",
    "l2_reg_embedding=1e-05, l2_reg_dnn=0, l2_reg_cin=0, \\\n",
    "# init_std=0.0001,\\\n",
    "seed=1024, dnn_dropout=0.2,dnn_activation='relu', \\\n",
    "dnn_use_bn=True, task='binary')\n",
    "#compiling the model\n",
    "model.compile(\"adam\", \"binary_crossentropy\",metrics=['binary_crossentropy'], )\n",
    "# training the model\n",
    "history = model.fit(train_model_input, train[target].values,\n",
    "                    batch_size=32, epochs=20, verbose=2, validation_split=0.1, )\n",
    "#predicting\n",
    "pred_ans_xdeep = model.predict(test_model_input, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b33b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456abf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "weigh= model.get_weights();    \n",
    "fpkl= open('xdeepfm_model.pkl', 'wb')    #Python 3     \n",
    "pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "fpkl.close()\n",
    "    \n",
    "fpkl= open('xdeepfm_model.pkl', 'rb')    #Python 3     \n",
    "weigh = pickle.load(fpkl)\n",
    "fpkl.close()\n",
    "\n",
    "my_model = xDeepFM(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(512, 512),\\\n",
    "cin_layer_size=(512, 512), \\\n",
    "cin_split_half=True, cin_activation='relu'\\\n",
    ",l2_reg_linear=1e-05,\\\n",
    "l2_reg_embedding=1e-05, l2_reg_dnn=0, l2_reg_cin=0, \\\n",
    "# init_std=0.0001,\\\n",
    "seed=1024, dnn_dropout=0.2,dnn_activation='relu', \\\n",
    "dnn_use_bn=True, task='binary')\n",
    "my_model.set_weights(weigh)\n",
    "# save the model\n",
    "# pickle.dump(model, open('xdeepfm_model.pkl', 'wb'))\n",
    "\n",
    "# # load the model\n",
    "# pickled_model = pickle.load(open('xdeepfm_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aef7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  model.fit(train_model_input, train[target].values,\n",
    "#                     batch_size=32, epochs=1, verbose=2, validation_split=0.1, )\n",
    "#     #predicting\n",
    "# pred_ans_xdeep = model.predict(test_model_input, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93f1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc = [(bool(pred_ans_xdeep[i][0] >= 0.5) and bool(test[target].values[i][0])) or not(bool(pred_ans_xdeep[i][0] < 0.5) and bool(test[target].values[i][0])) for i in range(len(pred_ans_xdeep))]\n",
    "sum(x == True for x in acc) / len(pred_ans_xdeep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53add2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepctr.models import xDeepFM\n",
    "from deepctr.feature_column  import  SparseFeat, DenseFeat,get_feature_names\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "data = pd.read_csv('./grocery_data2.csv')\n",
    "\n",
    "data['purchased'] = 1\n",
    "# categorising the features into sparse/dense feature set \n",
    "\n",
    "# dense features are quantitative in nature\n",
    "dense_features = ['age', 'price',]\n",
    "\n",
    "#sparse features are categorical in nature\n",
    "sparse_features = ['user_id', 'product_id', 'gender', 'location', 'category',  'brand']\n",
    "\n",
    "# data imputation for missing values\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "data[dense_features] = data[dense_features].fillna(0,)\n",
    "# creating target variable\n",
    "target = ['purchased']\n",
    "\n",
    "# encoding function\n",
    "def encoding(data,feat,encoder):\n",
    "    data[feat] = encoder.fit_transform(data[feat])\n",
    "# encoding for categorical features\n",
    "[encoding(data,feat,LabelEncoder()) for feat in sparse_features]\n",
    "# Using normalization for dense feature\n",
    "mms = MinMaxScaler(feature_range=(0,1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])\n",
    "# creating a 4 bit embedding for every sparse feature\n",
    "sparse_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].nunique(),embedding_dim=4) \\\n",
    "for i,feat in enumerate(sparse_features)]\n",
    "\n",
    "# creating a dense feat\n",
    "dense_feature_columns = [DenseFeat(feat, 1) for feat in dense_features]\n",
    "\n",
    "# features to be used for dnn part of xdeepfm\n",
    "dnn_feature_columns = sparse_feature_columns + dense_feature_columns\n",
    "# features to be used for linear part of xdeepfm\n",
    "linear_feature_columns = sparse_feature_columns + dense_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "items_lookup = {}\n",
    "users_lookup = {}\n",
    "\n",
    "for i in range(len(data)):\n",
    "    items_lookup[data['product_id'].iloc[i]] = data.iloc[i][['category','price','brand']]\n",
    "    users_lookup[data['user_id'].iloc[i]] = data.iloc[i][['age','location','gender']]\n",
    "\n",
    "# Get a list of all movie IDs\n",
    "all_productIds = data['product_id'].unique()\n",
    "\n",
    "user_item_set = set(zip(data['user_id'], data['product_id']))\n",
    "\n",
    "# This is the set of items that each user has interaction with\n",
    "user_items_dataset = set(zip(data['user_id'], data['product_id'], \\\n",
    "                         data['age'], data['gender'], \\\n",
    "                        data['location'], data['category'], \\\n",
    "                         data['price'], data['brand'], data['purchased']))\n",
    "\n",
    "def predict(user_id, top_num,include_item_bought_before=True):\n",
    "    \n",
    "    fpkl= open('xdeepfm_model.pkl', 'rb')    #Python 3     \n",
    "    weights = pickle.load(fpkl)\n",
    "    fpkl.close()\n",
    "\n",
    "    model = xDeepFM(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(512, 512),\\\n",
    "        cin_layer_size=(512, 512), \\\n",
    "        cin_split_half=True, cin_activation='relu'\\\n",
    "        ,l2_reg_linear=1e-05,\\\n",
    "        l2_reg_embedding=1e-05, l2_reg_dnn=0, l2_reg_cin=0, \\\n",
    "        # init_std=0.0001,\\\n",
    "        seed=1024, dnn_dropout=0.2,dnn_activation='relu', \\\n",
    "        dnn_use_bn=True, task='binary')\n",
    "    model.set_weights(weights)\n",
    "    \n",
    "    product_array, location_array, gender_array, age_array, category_array, price_array, brand_array = [],[],[],[],[],[],[]\n",
    "    \n",
    "    for item in data['product_id'].unique():\n",
    "        if (user_id, item) in user_item_set and not(include_item_bought_before):\n",
    "            continue\n",
    "        product_array.append(item)\n",
    "        location_array.append(users_lookup[user_id]['location'])\n",
    "        gender_array.append(users_lookup[user_id]['gender'])\n",
    "        age_array.append(users_lookup[user_id]['age'])\n",
    "        category_array.append(items_lookup[item]['category'])\n",
    "        price_array.append(items_lookup[item]['price'])\n",
    "        brand_array.append(items_lookup[item]['brand'])\n",
    "        \n",
    "    model_input = {'user_id':np.array([user_id] * len(age_array)).astype(int),\n",
    "                    'product_id': np.array(product_array).astype(int), \n",
    "                    'gender':np.array(gender_array).astype(int),\n",
    "                    'location':np.array(location_array).astype(int),\n",
    "                    'category':np.array(category_array).astype(int),\n",
    "                    'brand':np.array(brand_array).astype(int),\n",
    "                    'age':np.array(age_array).astype(float),\n",
    "                    'price':np.array(price_array).astype(int),}\n",
    "    \n",
    "    predictions = np.reshape(model.predict(model_input),(-1))\n",
    "    \n",
    "    return [data['product_id'].unique()[i] for i in np.argsort(predictions)[::-1][0:top_num].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e04580b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (test_model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5ede1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[57, 53, 3, 39, 2, 23, 55, 28, 4, 29]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(711,10,include_item_bought_before = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e671d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/extreme-deep-factorization-machine-xdeepfm-1ba180a6de78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b9bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
